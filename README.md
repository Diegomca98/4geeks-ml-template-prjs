# Template for Machine Learning projects

#### Module 13. Exploratory Data Analysis (Branch [exploratory-data-analysis](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/exploratory-data-analysis))
> Find patterns in your data in order to get insights and valuable information. Use that information to make decisions and generate better predictions. If your data is garbage, the output will be garbage: Clean your data to avoid poor quality outputs.

#### Module 14. Your first ML Alorithm (Branch: [logistic-regression](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/logistic-regression))
> During this module you will learn the basics of machine learning, the evaluation metrics and how to optimize your ML algo. We will start our journey with logistic regressions.

#### Module 15. Linear Regression (Branch: [linear-regression](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/linear-regression))
> Read the linear regression theory and run the code in the exploring linear regression notebook to practice. Then go to your project and predict the cost of a medical insurance using Linear Regression

#### Module 16. Regularized Linear Regression (Branch: [regularized-linear-regression](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/regularized-linear-regression))
>It is very important to avoid overfitting, so in this lesson you will learn about regularized linear regression models, which are a common way to avoid it.

#### Module 17.  Decision Tree (Branch: [decision-tree](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/decision-tree))
> This is one of the most used algorithms in the industry. Decision Tree's are used for both classification and regression problems. This algorithm makes decisions by building trees with nodes, leaves and branches to make decisions.

#### Module 18. Random Forest (Branch: [random-forest](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/random-forest))
> In this module we will add some randomness to our trees and build machine learning models using Random Forest.

#### Module 19. Boosting Algorithms (Branch: [boosting-algorithms](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/boosting-algorithms))
> In this lesson, we will learn about boosting techniques, specifically about gradient descent algorithm and XGBoost (extreme gradient descent).

#### Module 20. Naive Bayes (Branch: [naive-bayes](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/naive-bayes))
> Were you wondering when are you going to apply Bayes Theorem? Now it's the time. The Naive Bayes algorithm is one of the fastest algorithm and its based in the bayes theorem. We will use it for classification and also as a brief and simple introduction to NLP, which we'll learn deeper in another module.

#### Module 21. K-nearest-neighbors (Branch: [k-nearest-neighbors](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/k-nearest-neighbors))
> In this module we will learn about the k-nearest neighbors algorithm and we will dive into a very simple recommender system built with k-nearest neighbors.

#### Module 22. Unsupervised Learning (Branch: [k-means](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/k-means))
> In this module we will learn about a couple of unsupervised algorithms but we will focus on k-means for clustering with a very simple project to help you understand how to group data in clusters.

#### Module 23. Time Series Forecasting (Branches: [time-series-forecasting](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/time-series-forecasting) | [time-series-kaggle-competition](https://github.com/Diegomca98/4geeks-ml-template-prjs/tree/time-series-kaggle-competition))
> In this lesson, we will learn how to recognize and deal with time series when they are present in our datasets. This lesson's project will be a real time competition so get all your skills ready!


## Repository Structure
```
└── main
    ├── exploratory-data-analysis
    ├── logistic-regression
    ├── linear-regression
    ├── regularized-linear-regression
    ├── decision-tree
    ├── random-forest
    ├── boosting-algorithms
    ├── naive-bayes
    ├── k-nearest-neighbors
    ├── k-means
    ├── time-series-forecasting
    └── time-series-kaggle-competition
```
  

  